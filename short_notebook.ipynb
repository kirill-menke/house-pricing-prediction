{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Machine Learning – Moscow House Pricing (Short Notebook)\n",
    " Group 97: Ilaria Crivellari (ID: 567219), Kirill Menke (ID: 566609), Moritz Leugers (ID: 566563)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/proj/ciptmp/ny70konu/python3.9/site-packages')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import StackingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(0)\n",
    "\n",
    "# Read train/ test data\n",
    "apartments_train = pd.read_csv(\"data/apartments_train.csv\")\n",
    "buildings_train = pd.read_csv(\"data/buildings_train.csv\")\n",
    "apartments_test = pd.read_csv(\"data/apartments_test.csv\")\n",
    "buildings_test = pd.read_csv(\"data/buildings_test.csv\")\n",
    "metro_stations = pd.read_csv(\"data/metro_stations.csv\")\n",
    "\n",
    "# External datasources\n",
    "sub_area_centers = pd.read_csv(\"data/sberbank_sub_areas.csv\")\n",
    "sub_areas = gp.read_file('data/mo_kag_SRHM.shp')\n",
    "sberbank = pd.read_csv(\"data/sberbank.csv\")\n",
    "\n",
    "# Merge Tables: Apartments and Buildings\n",
    "train_df = apartments_train.merge(buildings_train, left_on='building_id', right_on='id', suffixes=('', '_r')).sort_values('id').set_index('id')\n",
    "test_df = apartments_test.merge(buildings_test, left_on='building_id', right_on='id', suffixes=('', '_r')).sort_values('id').set_index('id')\n",
    "\n",
    "# Merge train and test data\n",
    "data_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features\n",
    "data_df[\"street_and_address\"] = data_df.street + \" \" + data_df.address\n",
    "\n",
    "# Imputing coordinates outside of moscow and NaNs\n",
    "data_df.latitude[data_df.street_and_address == \"Бунинские Луга ЖК к2/2/1\"] = 55.5415152\n",
    "data_df.longitude[data_df.street_and_address == \"Бунинские Луга ЖК к2/2/1\"] = 37.4821752\n",
    "data_df.latitude[data_df.street_and_address == \"Бунинские Луга ЖК к2/2/2\"] = 55.5415152\n",
    "data_df.longitude[data_df.street_and_address == \"Бунинские Луга ЖК к2/2/2\"] = 37.4821752\n",
    "data_df.latitude[data_df.street_and_address == \"улица 1-я Линия 57\"] = 55.6324711\n",
    "data_df.longitude[data_df.street_and_address == \"улица 1-я Линия 57\"] = 37.4536057\n",
    "data_df.latitude[data_df.street_and_address == \"улица Центральная 75\"] = 55.5415152\n",
    "data_df.longitude[data_df.street_and_address == \"улица Центральная 75\"] = 37.4821752\n",
    "data_df.latitude[data_df.street_and_address == \"улица Центральная 48\"] = 55.5415152\n",
    "data_df.longitude[data_df.street_and_address == \"улица Центральная 48\"] = 37.4821752\n",
    "\n",
    "# NaNs\n",
    "data_df.latitude[data_df.street_and_address == \"пос. Коммунарка Москва А101 ЖК\"] = 55.5676692\n",
    "data_df.longitude[data_df.street_and_address == \"пос. Коммунарка Москва А101 ЖК\"] = 37.4816608\n",
    "\n",
    "# Encode streets to integers\n",
    "data_df[\"street\"] = LabelEncoder().fit_transform(data_df[\"street\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_array(lat1, lng1, lat2 = 55.752, lng2 = 37.617):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nearest sub_area based on its center\n",
    "bulding_locs = np.asarray(list(zip(data_df['latitude'], data_df['longitude'])))\n",
    "sub_area_locs = np.asarray(list(zip(sub_area_centers['longitude'], sub_area_centers['latitude'])))\n",
    "closest_sub_idx = np.argmin(haversine_distances(bulding_locs, sub_area_locs), axis=1)\n",
    "data_df[\"sub_area_\"] = sub_area_centers['sub_area'].iloc[closest_sub_idx].values\n",
    "\n",
    "# Mapping each building to its real sub_area\n",
    "geo_df = gp.GeoDataFrame(data_df, geometry=gp.points_from_xy(data_df.longitude, data_df.latitude))\n",
    "geo_df.crs = \"EPSG:4326\"\n",
    "data_df = gp.sjoin(sub_areas, geo_df, how='right', predicate='contains')\n",
    "data_df = data_df.drop([\"DISTRICT\", \"geometry\", \"OKATO\", \"OKTMO\", \"OKATO_AO\", \"index_left\"], axis=1)\n",
    "    \n",
    "# Add distance from city center\n",
    "data_df['center_distance'] = haversine_array(data_df['latitude'], data_df['longitude'])\n",
    "\n",
    "# Add closest metro_station\n",
    "metro_locs = np.asarray(list(zip(metro_stations['latitude'], metro_stations['longitude'])))\n",
    "closest_metro_dist = np.min(haversine_distances(bulding_locs, metro_locs), axis=1)\n",
    "data_df['closest_metro'] = closest_metro_dist\n",
    "\n",
    "# Add subarea related features from sberbank dataset\n",
    "data_df['mean_green_area'] = data_df['sub_area'].map(sberbank.groupby(\"sub_area\").mean().green_zone_part)\n",
    "\n",
    "# Ordinal Encoding for both sub_area variants\n",
    "data_df[\"sub_area\"] = LabelEncoder().fit_transform(data_df['sub_area'])\n",
    "data_df[\"sub_area_\"] = LabelEncoder().fit_transform(data_df['sub_area_'])\n",
    "\n",
    "# PCA transforming the two variants above\n",
    "pca = PCA(n_components=1)\n",
    "data_df[\"sub_area_pca\"] = pca.fit_transform(data_df[[\"sub_area\", \"sub_area_\"]]).squeeze()\n",
    "    \n",
    "# Add average price in the neighborhood\n",
    "tree = BallTree(data_df[[\"latitude\", \"longitude\"]])\n",
    "dist, ind = tree.query(data_df[[\"latitude\", \"longitude\"]], k=300)\n",
    "\n",
    "mean_sqm_price = []\n",
    "\n",
    "for rows in ind:\n",
    "    mean_sqm_price.append(np.nanmean(data_df['price'].iloc[rows] / np.log(data_df['area_total'].iloc[rows])))\n",
    "\n",
    "data_df[\"mean_sqm_price\"] = mean_sqm_price\n",
    "\n",
    "# Drop unimportant features\n",
    "data_df = data_df.drop([\"street_and_address\", \"address\", \"windows_court\", \"windows_street\", \"elevator_service\", \"elevator_passenger\", \"garbage_chute\", \n",
    "      \"layout\", \"heating\", \"elevator_without\", \"district\", \"phones\", \"building_id\", \"id_r\", \"material\", \"parking\"], axis = 1)\n",
    "\n",
    "data_df.fillna(-999, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMRegressor(max_depth=6, n_estimators=1200, learning_rate=0.1)\n",
    "model_xgb = XGBRegressor(n_estimators=1500, max_depth=6, learning_rate=0.1)\n",
    "model_cat = CatBoostRegressor(iterations=1000, depth=7, learning_rate=0.1, silent=True)\n",
    "model_extra = ExtraTreesRegressor(n_estimators=1000, random_state=0)\n",
    "model_hist = HistGradientBoostingRegressor(max_depth=7, max_iter=1000, learning_rate=0.1, random_state=0)\n",
    "model_ada_lgbm = AdaBoostRegressor(base_estimator = model_lgbm, n_estimators=50, random_state = 0)\n",
    "\n",
    "final_model = RidgeCV()\n",
    "\n",
    "base_learners = [\n",
    "    ('xgb_tree', model_xgb),\n",
    "    (\"lgbm\", model_lgbm),\n",
    "    ('catboost', model_cat),\n",
    "    ('extra_trees', model_extra),\n",
    "    ('hist_boost', model_hist),\n",
    "    (\"ada_lgbm\", model_ada_lgbm)\n",
    "]\n",
    "\n",
    "model_stacking = StackingRegressor(estimators=base_learners, final_estimator=final_model, cv=5)\n",
    "trans_stacking = TransformedTargetRegressor(regressor=model_stacking, func=np.log1p, inverse_func=np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test data\n",
    "X_train = data_df[0:len(train_df)]\n",
    "X_train = X_train.drop('price', axis=1)\n",
    "X_test = data_df[len(train_df):len(data_df)].drop('price', axis=1)\n",
    "y_train = train_df['price']\n",
    "\n",
    "y_pred = trans_stacking.fit(X_train, y_train).predict(X_test)\n",
    "result = np.column_stack((X_test.index.to_numpy(), y_pred))\n",
    "np.savetxt(r'./result.csv', result, fmt=['%d', ' %.3f'], delimiter=',', header=\"id,price_prediction\", comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
